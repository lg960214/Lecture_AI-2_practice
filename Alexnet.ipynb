{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from distutils import util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 227, 227])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "            transforms.Resize((227, 227)),\n",
    "            transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\", # Download True일 시, 데이터를 다운받을 경로 // Download False일 시, 데이터가 존재하는 경로\n",
    "    train=True,  # Training data\n",
    "    download=False,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False, # Test data\n",
    "    download=False,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 데이터로더를 생성합니다.\n",
    "train_dataloader = DataLoader(dataset=training_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model consisting of layers propsed by AlexNet paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        \"\"\"\n",
    "        Define and allocate layers for this neural net.\n",
    "        Args:\n",
    "            num_classes (int): number of classes to predict with this model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # input size should be : (b x 3 x 227 x 227)\n",
    "        # The image in the original paper states that width and height are 224 pixels, but\n",
    "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
    "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
    "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
    "        )\n",
    "        # classifier is just a name for linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "        )\n",
    "        self.init_bias()  # initialize bias\n",
    "\n",
    "    def init_bias(self):\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
    "        nn.init.constant_(self.net[4].bias, 1)\n",
    "        nn.init.constant_(self.net[10].bias, 1)\n",
    "        nn.init.constant_(self.net[12].bias, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input through the net.\n",
    "        Args:\n",
    "            x (Tensor): input tensor\n",
    "        Returns:\n",
    "            output (Tensor): output tensor\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 227, 227])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# -- settings\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# -- dataset & augmentation\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "            transforms.Resize((227, 227)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\", # Download True일 시, 데이터를 다운받을 경로 // Download False일 시, 데이터가 존재하는 경로\n",
    "    train=True,  # Training data\n",
    "    download=False,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False, # Test data\n",
    "    download=False,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "\n",
    "# 데이터로더를 생성합니다.\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(dataset=training_data,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=use_cuda,\n",
    "    num_workers=multiprocessing.cpu_count()//2,\n",
    "    shuffle=True)\n",
    "    \n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=use_cuda,\n",
    "    num_workers=multiprocessing.cpu_count()//2,\n",
    "    shuffle=False)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): AlexNet(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (5): ReLU()\n",
      "      (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "      (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU()\n",
      "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.5, inplace=False)\n",
      "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -- model\n",
    "\n",
    "model = AlexNet().to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "        params=model.parameters(),\n",
    "        lr=0.01,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.302752  [    0/50000]\n",
      "loss: 2.300008  [ 6400/50000]\n",
      "loss: 2.296355  [12800/50000]\n",
      "loss: 2.294404  [19200/50000]\n",
      "loss: 2.309405  [25600/50000]\n",
      "loss: 2.301866  [32000/50000]\n",
      "loss: 2.311103  [38400/50000]\n",
      "loss: 2.296681  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302927 \n",
      "\n",
      "loss: 2.307286  [    0/50000]\n",
      "loss: 2.301385  [ 1600/50000]\n",
      "loss: 2.303610  [ 3200/50000]\n",
      "loss: 2.304586  [ 4800/50000]\n",
      "loss: 2.308570  [ 6400/50000]\n",
      "loss: 2.301448  [ 8000/50000]\n",
      "loss: 2.304954  [ 9600/50000]\n",
      "loss: 2.309008  [11200/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302927 \n",
      "\n",
      "loss: 2.307623  [    0/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ca86db9b25b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "\n",
    "    for idx, train_batch in enumerate(train_dataloader):\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = F.cross_entropy(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            loss, current = loss.item(), idx * len(X)\n",
    "            size = len(train_dataloader.dataset)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        size = len(test_dataloader.dataset)\n",
    "        num_batches = len(test_dataloader)\n",
    "\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model(X)\n",
    "            test_loss += F.cross_entropy(test_pred, y).item()\n",
    "            correct += (torch.argmax(test_pred, dim=-1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(torch.Tensor([1,2,3,1]), dim=-1)==torch.Tensor([1,2,3,4,5,6,7])).type(torch.float).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
